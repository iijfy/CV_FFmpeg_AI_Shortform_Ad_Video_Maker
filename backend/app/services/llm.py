"""
LLM 

ì—­í• :
- ë©”ë‰´/ê°€ê²Œëª…/í†¤(+ ì˜µì…˜ ì •ë³´)ë¥¼ ë°›ì•„ì„œ
  - 18ì´ˆ ì‡¼ì¸ ìš© ìº¡ì…˜ 8~10ì¤„
  - 3~5ë¬¸ì¥ í”„ë¡œëª¨ì…˜ ë¬¸êµ¬
  - í•´ì‹œíƒœê·¸ 5~12ê°œ
ë¥¼ ìƒì„±.

ëª©í‘œ(ì •ë³´ì „ë‹¬ í¬í•¨):
- ìœ íŠœë¸Œ ì‡¼ì¸ ì²˜ëŸ¼ "í›… â†’ ì •ë³´ â†’ ì‹ ë¢° â†’ í˜œíƒ â†’ ê¸´ê¸‰/í•œì • â†’ CTA" íë¦„ì„ ê°–ê²Œ í•œë‹¤.
- ê³¼ì¥/í—ˆìœ„ íš¨ëŠ¥/ì˜í•™ì  ì£¼ì¥ ê¸ˆì§€.
- LLM í‚¤ê°€ ì—†ì–´ë„ fallbackì´ 'í—ˆì ‘'í•˜ì§€ ì•Šê²Œ í…œí”Œë¦¿ì„ ê°•í™”í•œë‹¤.
"""

from __future__ import annotations

import json
import re
import random
from dataclasses import dataclass
from typing import List, Optional

from backend.app.core.config import settings
from backend.app.core.logger import get_logger

logger = get_logger(__name__)


@dataclass
class LLMOutput:
    caption_lines: List[str]
    promo_text: str
    hashtags: List[str]


# ìœ í‹¸
def _clean(s: Optional[str]) -> Optional[str]:
    if s is None:
        return None
    s = str(s).strip()
    return s or None


def _tone_profile(tone: str) -> dict:
    t = (tone or "ê°ì„±").strip()

    # í†¤ë³„ ë§íˆ¬/ë‹¨ì–´ ì„ íƒ ê°€ì´ë“œ
    if t in ["í™", "í™í•©", "ìŠ¤íŠ¸ë¦¿"]:
        return {
            "hook": ["ì§€ê¸ˆ ì´ê±° ì•ˆ ë¨¹ìœ¼ë©´ ì†í•´", "ì´ ì¡°í•© ë¯¸ì³¤ë‹¤", "ìš”ì¦˜ ì´ê²Œ ìœ í–‰ì´ì•¼"],
            "style": "ì§§ê³  ë¦¬ë“¬ê° ìˆê²Œ, êµ¬ì–´ì²´, ì•½ê°„ ì¿¨í•˜ê²Œ",
            "cta": ["ì§€ê¸ˆ ë°”ë¡œ ì°ê³  ê°€", "ì˜¤ëŠ˜ ã„±ã„±", "ì§€ê¸ˆ ì£¼ë¬¸ ã„±"],
        }
    if t in ["ê³ ê¸‰", "í”„ë¦¬ë¯¸ì—„", "ëŸ­ì…”ë¦¬"]:
        return {
            "hook": ["ì˜¤ëŠ˜ì€ ì œëŒ€ë¡œ ë¨¹ì", "í•œ ë¼ë¼ë„ í’ˆê²© ìˆê²Œ", "ì…ì•ˆì—ì„œ ì •ë¦¬ë˜ëŠ” ë§›"],
            "style": "ì •ëˆëœ ë¬¸ì¥, ê³¼í•˜ì§€ ì•Šê²Œ, ì‹ ë¢°ê° ìˆê²Œ",
            "cta": ["ì˜ˆì•½/ë°©ë¬¸ ë¬¸ì˜ ì£¼ì„¸ìš”", "ì§€ê¸ˆ ë°”ë¡œ í™•ì¸í•´ë³´ì„¸ìš”", "ì˜¤ëŠ˜ í•œì • ì¶”ì²œë“œë¦½ë‹ˆë‹¤"],
        }
    if t in ["ê°€ì„±ë¹„", "ì‹¤ì†", "ì €ë ´"]:
        return {
            "hook": ["ê°€ê²© ë³´ê³  ë‘ ë²ˆ ë†€ëŒ", "ì´ í€„ë¦¬í‹°ì— ì´ ê°€ê²©?", "ê°€ì„±ë¹„ë¡œ ëë‚´ì"],
            "style": "ì •ë³´ ì¤‘ì‹¬ + ì§ì„¤, ë¶€ë‹´ ì—†ì´",
            "cta": ["ì§€ê¸ˆ ë°”ë¡œ ì£¼ë¬¸!", "ì˜¤ëŠ˜ ë“í…œí•˜ì", "ê°€ì„±ë¹„ ì°¾ìœ¼ë©´ ì—¬ê¸°"],
        }

    # ê¸°ë³¸: ê°ì„±
    return {
        "hook": ["ì§€ê¸ˆ ë”± ìƒê°ë‚˜ëŠ” ë§›", "ì˜¤ëŠ˜ í•˜ë£¨, ì´ê±¸ë¡œ ë³´ìƒ", "ì…ë§› ëŒì•„ì˜¤ëŠ” ìˆœê°„"],
        "style": "ê°ì„± + ì •ë³´ ê· í˜•, ë¶€ë“œëŸ½ê²Œ",
        "cta": ["ì˜¤ëŠ˜ í•œ ë²ˆ ë“¤ëŸ¬ë³´ì„¸ìš”", "ì§€ê¸ˆ ì£¼ë¬¸/ë°©ë¬¸ í™˜ì˜", "ì§€ê¸ˆ ë°”ë¡œ ë§›ë³´ì„¸ìš”"],
    }


def _shorts_bank(tone: str) -> dict:
    """
    ì‡¼ì¸  ìë§‰ìš© ë¬¸ì¥ ë±…í¬(í†¤ë³„)
    - ë„ˆë¬´ ê´‘ê³  í‹° ë‚˜ëŠ” í‘œí˜„/ê³¼ì¥ì€ í”¼í•˜ê³ 
    - ì§§ê³  ë¦¬ë“¬ê° ìˆê²Œ(10~16ì ì¤‘ì‹¬)
    """
    t = (tone or "ê°ì„±").strip()

    if t in ["í™", "í™í•©", "ìŠ¤íŠ¸ë¦¿"]:
        return {
            "sensory": ["ë¹„ì£¼ì–¼ ë¯¸ì³¤ë‹¤", "í–¥ ì˜¬ë¼ì˜¨ë‹¤", "í•œì…ì— ë", "ë°”ì‚­+ì´‰ì´‰", "ë‹¨ì§  ë°¸ëŸ°ìŠ¤"],
            "usp": ["ìš”ì¦˜ ì´ ì¡°í•©", "ì…ë§› ë³µêµ¬ë¨", "ì¤‘ë…ì£¼ì˜", "ì¹œêµ¬ë‘ ã„±ã„±", "í˜¼ë°¥ë„ OK"],
            "trust": ["ì‚¬ì§„ ê·¸ëŒ€ë¡œ OK", "ì¬ë£Œ ì•„ë‚Œì—†ìŒ", "ë§›ì€ ë³´ì¥", "ê¸°ë³¸ê¸° íƒ„íƒ„"],
            "urgency": ["ì§€ê¸ˆì´ íƒ€ì´ë°", "ì˜¤ëŠ˜ ì•ˆ ë¨¹ìœ¼ë©´ ì†í•´", "ì €ë…ì€ ì´ê±°"],
            "cta": ["ì €ì¥í•˜ê³  ê°€ì", "ì˜¤ëŠ˜ ã„±ã„±", "ì§€ê¸ˆ ì£¼ë¬¸ ã„±", "ì§€ê¸ˆ ì°ê³  ê°€"],
        }

    if t in ["ê³ ê¸‰", "í”„ë¦¬ë¯¸ì—„", "ëŸ­ì…”ë¦¬"]:
        return {
            "sensory": ["í•œì…ì— ì •ë¦¬", "í–¥ì´ ë‹¤ë¥´ë‹¤", "ì‹ê°ì´ ê¹”ë”", "ëë§›ì´ ê³ ê¸‰"],
            "usp": ["í•œ ë¼ì˜ í’ˆê²©", "ì •ì„± ëŠê»´ì§", "ë°¸ëŸ°ìŠ¤ ì¢‹ë‹¤", "ê³¼í•˜ì§€ ì•Šê²Œ"],
            "trust": ["ì‚¬ì§„ ê·¸ëŒ€ë¡œ OK", "ì¬ë£Œ í€„ë¦¬í‹°", "ê¸°ë³¸ì´ íƒ„íƒ„", "ê¹”ë”í•˜ê²Œ ì¤€ë¹„"],
            "urgency": ["ì˜¤ëŠ˜ì€ ì—¬ê¸°", "ì§€ê¸ˆ ë”± ì¢‹ì•„ìš”", "ì €ë… ì¶”ì²œ"],
            "cta": ["ì˜¤ëŠ˜ í•œ ë²ˆ ë“¤ëŸ¬ìš”", "ì§€ê¸ˆ í™•ì¸í•´ë³´ì„¸ìš”", "ì˜ˆì•½/ë°©ë¬¸ ë¬¸ì˜"],
        }

    if t in ["ê°€ì„±ë¹„", "ì‹¤ì†", "ì €ë ´"]:
        return {
            "sensory": ["ì–‘ ì‹¤í™”ëƒ", "ë¹„ì£¼ì–¼ í•©ê²©", "í•œì…ì— ë“ ë“ ", "ëê¹Œì§€ ëœ¨ëˆ"],
            "usp": ["ê°€ì„±ë¹„ë¡œ ë", "ë°°ë¶€ë¥´ê²Œ OK", "í˜¼ë°¥ë„ êµ¿", "ì„¸íŠ¸ë¡œ ì´ë“"],
            "trust": ["ì‚¬ì§„ ê·¸ëŒ€ë¡œ OK", "ì–‘ ì†ì´ì§€ ì•ŠìŒ", "ì¬ë°©ë¬¸ ê°", "ë§›ì€ í™•ì‹¤"],
            "urgency": ["ì˜¤ëŠ˜ ë©”ë‰´ í™•ì •", "ì§€ê¸ˆì´ íƒ€ì´ë°", "ì €ë… ê³ ë¯¼ ë"],
            "cta": ["ì§€ê¸ˆ ì£¼ë¬¸!", "ì €ì¥í•´ë‘ì", "ê°€ì„±ë¹„ ì°¾ìœ¼ë©´ ì—¬ê¸°"],
        }

    # ê¸°ë³¸: ê°ì„±
    return {
        "sensory": ["ì…ë§› ëŒì•„ì˜¨ë‹¤", "í•œì…ì— ìœ„ë¡œ", "ë”°ëˆí•˜ê²Œ ë”±", "ì´‰ì´‰í•˜ê²Œ ì«™"],
        "usp": ["ì˜¤ëŠ˜ ë³´ìƒ ì™„ë£Œ", "ê¸°ë¶„ ì¢‹ì•„ì§€ëŠ” ë§›", "ë¶€ë‹´ ì—†ì´ ì¢‹ì•„", "ë”± ìƒê°ë‚˜ëŠ” ë§›"],
        "trust": ["ì‚¬ì§„ ê·¸ëŒ€ë¡œ OK", "ì •ì„± ë‹´ì•˜ì–´ìš”", "ê¸°ë³¸ì´ ì¢‹ì•„ìš”", "ê¹”ë”í•˜ê²Œ ì¤€ë¹„"],
        "urgency": ["ì˜¤ëŠ˜ì€ ì´ê±°", "ì§€ê¸ˆì´ íƒ€ì´ë°", "ì €ë…ìœ¼ë¡œ ë”±"],
        "cta": ["ì €ì¥í•˜ê³  ê°€ìš”", "ì˜¤ëŠ˜ í•œ ë²ˆ ë“¤ëŸ¬ìš”", "ì§€ê¸ˆ ë°”ë¡œ ë§›ë³´ì"],
    }


def _normalize_line(s: str) -> str:
    # ë„ˆë¬´ ê¸´ ê³µë°±/ê¸°í˜¸ ì •ë¦¬ (ê°ì„± ì‚´ë¦¬ë˜ ê¹¨ì§ ë°©ì§€)
    s = (s or "").strip()
    s = re.sub(r"\s+", " ", s)
    s = s.replace("â€¦", ".")
    return s.strip()


def _cap_len(s: str, max_chars: int = 16) -> str:
    # ì‡¼ì¸  ìë§‰ì€ ë„ˆë¬´ ê¸¸ë©´ ë‹µë‹µí•¨. ëŒ€ëµ 10~16ì ì„ ì—ì„œ ëŠê¸°.
    s = _normalize_line(s)
    if len(s) <= max_chars:
        return s
    return s[: max_chars - 1].rstrip() + "â€¦"


def _hashtags(menu_name: str, store_name: Optional[str], location: Optional[str]) -> List[str]:
    tags = []
    base = [
        f"#{menu_name}",
        "#ë§›ì§‘",
        "#ì˜¤ëŠ˜ì˜ë©”ë‰´",
        "#ë¨¹ë°©",
        "#ì‡¼ì¸ ",
        "#ë°°ë‹¬",
        "#í¬ì¥",
    ]
    tags.extend(base)

    if store_name:
        tags.append(f"#{store_name.replace(' ', '')}")
    if location:
        tags.append(f"#{location.replace(' ', '')}")

    out = []
    seen = set()
    for t in tags:
        if t not in seen and len(out) < 12:
            out.append(t)
            seen.add(t)
    return out



# ì´ëª¨ì§€(ì ˆì œ) - fallbackì—ë§Œ ì‚¬ìš©
def _emoji_pool(tone: str) -> List[str]:
    t = (tone or "ê°ì„±").strip()
    if t in ["í™", "í™í•©", "ìŠ¤íŠ¸ë¦¿"]:
        return ["ğŸ”¥", "âš¡ï¸", "ğŸ˜‹", "ğŸ’¥", "ğŸ–¤"]
    if t in ["ê³ ê¸‰", "í”„ë¦¬ë¯¸ì—„", "ëŸ­ì…”ë¦¬"]:
        return ["âœ¨", "ğŸ·", "ğŸ¤", "ğŸŒ¿", "â­ï¸"]
    if t in ["ê°€ì„±ë¹„", "ì‹¤ì†", "ì €ë ´"]:
        return ["ğŸ’¸", "âœ…", "ğŸ½ï¸", "ğŸ˜‹", "ğŸ”¥"]
    return ["âœ¨", "ğŸ˜‹", "ğŸ”¥", "ğŸŒ™", "ğŸ¤"]


def _looks_like_info_line(s: str) -> bool:
    """
    ê°€ê²©/ìœ„ì¹˜/í˜œíƒ ê°™ì€ 'ì •ë³´ ì¤„' íŒë³„
    - ì´ëŸ° ì¤„ì—” ì´ëª¨ì§€ë¥¼ ë¶™ì´ë©´ ìœ ì¹˜í•´ ë³´ì¼ í™•ë¥ ì´ ë†’ì•„ì„œ ê¸ˆì§€
    """
    s = (s or "").strip()
    if not s:
        return False

    # ê°€ê²© ëŠë‚Œ
    if any(x in s for x in ["ì›", "â‚©", "ë§Œì›", "ì²œì›", "ì„¸íŠ¸", "1ì¸", "2ì¸"]):
        return True

    # ìœ„ì¹˜ ëŠë‚Œ
    if any(x in s for x in ["ì—­", "ë™", "êµ¬", "ì‹œ", "ê·¼ì²˜", "ì•", "ì˜†", "ê³¨ëª©", "ê±°ë¦¬"]):
        return True

    # í˜œíƒ/ì´ë²¤íŠ¸ ëŠë‚Œ
    if any(x in s for x in ["í• ì¸", "ì¦ì •", "ì„œë¹„ìŠ¤", "ì´ë²¤íŠ¸", "ì¿ í°", "í˜œíƒ", "ë¦¬ë·°"]):
        return True

    return False


def _add_emojis_fallback(lines: List[str], tone: str, max_emojis: int = 2) -> List[str]:
    """
    fallback ì „ìš©: ì´ëª¨ì§€ë¥¼ 'ë”±' ëª‡ ì¤„ì—ë§Œ ì¶”ê°€
    ë£°:
    - ì¤„ë‹¹ ìµœëŒ€ 1ê°œ
    - ì „ì²´ max_emojisê°œë§Œ
    - ì •ë³´ì¤„(ê°€ê²©/ìœ„ì¹˜/í˜œíƒ)ì—ëŠ” ì ˆëŒ€ ë¶™ì´ì§€ ì•ŠìŒ
    """
    if not lines:
        return lines

    pool = _emoji_pool(tone)

    candidates = []
    for i, s in enumerate(lines):
        s = (s or "").strip()
        if not s:
            continue
        if _looks_like_info_line(s):
            continue
        # ì´ë¯¸ ì´ëª¨ì§€/íŠ¹ìˆ˜ê¸°í˜¸ê°€ ìˆìœ¼ë©´ ê³¼í•´ì§€ë‹ˆ ìŠ¤í‚µ
        if any(ch in s for ch in ["ğŸ”¥", "âœ¨", "ğŸ˜‹", "â­", "ğŸ’¸", "âœ…", "âš¡", "ğŸ’¥", "ğŸ¤", "ğŸ–¤", "ğŸŒ™", "ğŸ½", "ğŸ·", "ğŸŒ¿"]):
            continue
        candidates.append(i)

    if not candidates:
        return lines

    k = min(max_emojis, len(candidates))
    picks = random.sample(candidates, k=k)

    out = lines[:]
    for idx in picks:
        out[idx] = f"{random.choice(pool)} {out[idx]}".strip()

    return out



# fallback (í‚¤ ì—†ì„ ë•Œë„ "ê´œì°®ê²Œ")
def _fallback(
    menu_name: str,
    store_name: Optional[str],
    tone: str,
    n_lines: int,
    price: Optional[str] = None,
    location: Optional[str] = None,
    benefit: Optional[str] = None,
    cta: Optional[str] = None,
) -> LLMOutput:
    store = store_name or "ìš°ë¦¬ ê°€ê²Œ"
    tonep = _tone_profile(tone)
    bank = _shorts_bank(tone)

    hook = tonep["hook"][0]  # í†¤ í”„ë¡œí•„ì˜ í›…
    cta_text = cta or random.choice(bank["cta"])

    # ì •ë³´ëŠ” í•œ ì¤„ì— 1ê°œë§Œ
    if price:
        info = f"{price}ë©´ ë"
    elif benefit:
        info = benefit
    elif location:
        info = location
    else:
        info = random.choice(bank["urgency"])

    sensory = random.choice(bank["sensory"])
    usp = random.choice(bank["usp"])
    trust = random.choice(bank["trust"])

    base_lines = [
        hook,
        f"{menu_name} ë‚˜ì™”ìŒ",
        sensory,
        usp,
        trust,
        info,
        cta_text,
    ]

    n = max(4, min(12, int(n_lines or 6)))

    lines = base_lines[:n]
    if len(lines) < n:
        fillers = ["í•œì…ì— ë", "ìœ¡ì¦™ í„°ì§„ë‹¤", "ì˜¤ëŠ˜ ë©”ë‰´ í™•ì •", "ì €ì¥í•´ë‘ì"]
        k = 0
        while len(lines) < n and k < 10:
            lines.insert(-1, fillers[k % len(fillers)])
            k += 1

    # ê¸¸ì´ ìº¡
    lines = [_cap_len(_normalize_line(x), 16) for x in lines]

    # fallbackì—ë§Œ ì ˆì œ ì´ëª¨ì§€ ì¶”ê°€(ìµœëŒ€ 2ê°œ)
    lines = _add_emojis_fallback(lines, tone, max_emojis=2)

    promo_parts = [
        f"{store}ì˜ {menu_name} ì¶”ì²œ!",
        f"{('ê°€ê²©ì€ ' + price) if price else 'ì§€ê¸ˆ ë§‰ ì¤€ë¹„í–ˆì–´ìš”.'}",
        f"{('ìœ„ì¹˜ëŠ” ' + location) if location else ''}".strip(),
        f"{benefit if benefit else 'ë”°ëˆí•˜ê²Œ ì¤€ë¹„í•´ì„œ ë°”ë¡œ ë“œì‹¤ ìˆ˜ ìˆì–´ìš”.'}",
        f"ì£¼ë¬¸/ë°©ë¬¸ì€ {cta_text}.",
    ]
    promo = " ".join([p for p in promo_parts if p])

    tags = _hashtags(menu_name, store_name, location)
    return LLMOutput(lines, promo, tags)



# OpenAI í˜¸ì¶œ (ìˆìœ¼ë©´ ë” ìì—°ìŠ¤ëŸ½ê²Œ)
def _parse_json_safely(text: str) -> Optional[dict]:
    """
    ëª¨ë¸ì´ JSON ì™¸ í…ìŠ¤íŠ¸ë¥¼ ì„ì–´ë„ ìµœëŒ€í•œ ë³µêµ¬í•˜ëŠ” íŒŒì„œ
    """
    if not text:
        return None

    text = text.strip()

    try:
        return json.loads(text)
    except Exception:
        pass

    m = re.search(r"\{.*\}", text, flags=re.DOTALL)
    if not m:
        return None

    chunk = m.group(0)
    try:
        return json.loads(chunk)
    except Exception:
        return None


def generate_copy(
    menu_name: str,
    store_name: Optional[str],
    tone: str,
    n_lines: int = 6,
    price: Optional[str] = None,
    location: Optional[str] = None,
    benefit: Optional[str] = None,
    cta: Optional[str] = None,
) -> LLMOutput:
    """
    LLMì´ ìˆìœ¼ë©´ LLM, ì—†ìœ¼ë©´ fallback.

    n_lines:
    - routes.pyì—ì„œ ì»· ìˆ˜(target_cuts)ì— ë§ì¶° ë„˜ê²¨ì¤Œ (ë³´í†µ 6)
    """
    menu_name = _clean(menu_name) or "ì˜¤ëŠ˜ì˜ ë©”ë‰´"
    store_name = _clean(store_name)
    tone = _clean(tone) or "ê°ì„±"

    price = _clean(price)
    location = _clean(location)
    benefit = _clean(benefit)
    cta = _clean(cta)

    n_lines = max(4, min(12, int(n_lines or 6)))

    if not settings.OPENAI_API_KEY:
        logger.info("OPENAI_API_KEYê°€ ì—†ì–´ fallback ë¬¸êµ¬ë¥¼ ì‚¬ìš©í•©ë‹ˆë‹¤.")
        return _fallback(
            menu_name=menu_name,
            store_name=store_name,
            tone=tone,
            n_lines=n_lines,
            price=price,
            location=location,
            benefit=benefit,
            cta=cta,
        )

    import requests

    store_str = store_name or "ë¯¸ê¸°ì¬"
    price_str = price or "ë¯¸ê¸°ì¬"
    location_str = location or "ë¯¸ê¸°ì¬"
    benefit_str = benefit or "ë¯¸ê¸°ì¬"
    cta_str = cta or "ë¯¸ê¸°ì¬"

    prompt = f"""
ë„ˆëŠ” í•œêµ­ ìŒì‹ì  ìœ íŠœë¸Œ ì‡¼ì¸ (9:16, 18ì´ˆ) ê´‘ê³  ìë§‰ ì¹´í”¼ë¼ì´í„°ë‹¤.
10~30ëŒ€ ë‚¨ë…€ë…¸ì†Œ ìƒëŒ€ë¡œ ì¬ë¯¸ìˆê²Œ ìŒì‹ì /ë©”ë‰´ë¥¼ í™ë³´í•˜ëŠ” ë¬¸êµ¬ë¥¼ ë§Œë“ ë‹¤.
ë„ˆë¬´ ì§§ê²ŒëŠ” í•˜ì§€ë§ê³  ì ì–´ë„ 6ì ì´ìƒì€ ë˜ê²Œ í•œë‹¤.
ëª©í‘œ: "ì§§ê²Œ, ë°•ì ìˆê²Œ, ì €ì¥/ë°©ë¬¸ì„ ë¶€ë¥´ê²Œ, ì¬ë¯¸ ìˆê²Œ" ë§Œë“œëŠ” ìë§‰.


ì…ë ¥:
- ê°€ê²Œëª…: {store_str}
- ë©”ë‰´ëª…: {menu_name}
- í†¤: {tone}
- ê°€ê²©: {price_str}
- ìœ„ì¹˜: {location_str}
- í˜œíƒ: {benefit_str}
- CTA: {cta_str}

ì¶œë ¥ì€ JSONë§Œ:
{{
  "caption_lines": ["...","..."],
  "promo_text": "3~5ë¬¸ì¥",
  "hashtags": ["#..."]
}}

[caption_lines ê·œì¹™] (ê°€ì¥ ì¤‘ìš”)
- ì •í™•íˆ {n_lines}ì¤„.
- ê° ì¤„: 10~16ì(ê³µë°± í¬í•¨). ê¸¸ë©´ ìë¥´ê³  ë‹¤ì‹œ ì¨ë¼.
- ë¬¸ì¥ë¶€í˜¸/ëŠë‚Œí‘œ/ì´ëª¨ì§€ ë‚¨ë°œ ê¸ˆì§€(ì´ëª¨ì§€ëŠ” ì „ì²´ 0~1ê°œë§Œ).
- 'ìµœê³ ì˜/ì™„ë²½í•œ/í•´ë“œë¦½ë‹ˆë‹¤/ê°•ì¶”/ëŒ€ë°•/ë¬´ì¡°ê±´' ê°™ì€ ê´‘ê³  í‹° ë‚˜ëŠ” ë§íˆ¬ ê¸ˆì§€.
- í•œ ì¤„ì—” ì •ë³´ 1ê°œë§Œ(ê°€ê²©/ìœ„ì¹˜/í˜œíƒ ì¤‘ í•˜ë‚˜). ë¯¸ê¸°ì¬ë©´ ë„£ì§€ ë§ˆë¼.
- êµ¬ì–´ì²´ + ë¦¬ë“¬ê°. â€œì§§ì€ ë§â€ ìœ„ì£¼.
- ë§ˆì§€ë§‰ ì¤„ì€ ë°˜ë“œì‹œ CTA(ì €ì¥/ë°©ë¬¸/ì£¼ë¬¸ ìœ ë„).


[ì´ëª¨ì§€ ê·œì¹™]
- ìº¡ì…˜ ì „ì²´ì— ì´ëª¨ì§€ëŠ” "ì •í™•íˆ 1ê°œ"ë§Œ ì‚¬ìš©í•´ë¼.
- ê·¸ 1ê°œëŠ” "ì²« ì¤„(í›…)"ì—ë§Œ ë¶™ì—¬ë¼.
- ì‚¬ìš© ê°€ëŠ¥í•œ ì´ëª¨ì§€: ğŸ”¥ â­ï¸ ğŸœ ğŸ– ğŸ¥Ÿ ğŸ£ ğŸ§€ ğŸ¥© ğŸŒ¶ï¸
- ë‹¤ë¥¸ ì´ëª¨ì§€ ê¸ˆì§€.

[ì „ê°œ í…œí”Œë¦¿]
1) í›…(ì‹œì„  ì¡ê¸°) 
2) ë¹„ì£¼ì–¼/ì‹ê°/í–¥(ê°ê° 1ê°œ)
3) ì¥ì (ê°€ì„±ë¹„/í‘¸ì§/ë§¤ìš´ë§›/ë‹´ë°± ë“± 1ê°œ)
4) (ì„ íƒ) ê°€ê²© or í˜œíƒ (1ê°œë§Œ)
5) (ì„ íƒ) ìœ„ì¹˜/ë™ë„¤ (1ê°œë§Œ)
6) CTA(ì €ì¥/ì˜¤ëŠ˜ê°€ì/ì§€ê¸ˆì£¼ë¬¸)

[ì¢‹ì€ ì˜ˆ]
- "ğŸ”¥ ë¹„ì£¼ì–¼ ë¯¸ì³¤ë„¤ ì´ê±° ë³´ì—¬?"
- "ìœ¡ì¦™ì´.. ì´ê±°ë¨¸ì„?!"
- "ë°”ì‚­+ì´‰ì´‰í•œ ì™„ë²½ ì¡°í•© ë°°ê³ íŒŒ!!"
- "ì´ì •ë„ë©´ ê°€ì„±ë¹„ ë ì•„ë‹˜?"
- "ê²€ìƒ‰í•˜ëŠë¼ í˜ ë¹¼ì§€ë§ˆ!"
- "í•œë²ˆì˜¤ë©´ ë˜ ì˜¤ê²Œ ë ê±¸?!"
- "í›„ê¸°ë§Œ ë´ë„ ë§›ì§‘ì´ì§€?^^"
- "ì˜¤ëŠ˜ ì €ë…ì€.. ì—¬ê¸°ë‹¤! ã…‹ã…‹"
"""

    url = "https://api.openai.com/v1/chat/completions"
    headers = {"Authorization": f"Bearer {settings.OPENAI_API_KEY}"}
    payload = {
        "model": "gpt-4o-mini",
        "messages": [
            {"role": "system", "content": "You write short-form Korean ad copy with clear structure and strong rhythm."},
            {"role": "user", "content": prompt},
        ],
        "temperature": 0.9,
        "top_p": 0.9,
        "frequency_penalty": 0.4,
        "presence_penalty": 0.2,
    }

    try:
        r = requests.post(url, headers=headers, json=payload, timeout=60)
        r.raise_for_status()
        content = r.json()["choices"][0]["message"]["content"]
        data = _parse_json_safely(content)

        if not data:
            raise ValueError("JSON parse failed")

        lines = data.get("caption_lines") or []
        promo = data.get("promo_text") or ""
        tags = data.get("hashtags") or []

        lines = [str(x) for x in lines][:n_lines]
        if len(lines) < n_lines:
            fb = _fallback(menu_name, store_name, tone, n_lines, price, location, benefit, cta).caption_lines
            lines += fb[len(lines):n_lines]

        lines = [_cap_len(_normalize_line(x), 16) for x in lines]

        promo = str(promo).strip()
        if not promo:
            promo = _fallback(menu_name, store_name, tone, n_lines, price, location, benefit, cta).promo_text

        if not isinstance(tags, list) or len(tags) < 3:
            tags = _hashtags(menu_name, store_name, location)
        else:
            out = []
            seen = set()
            for t in tags:
                t = str(t).strip()
                if not t:
                    continue
                if not t.startswith("#"):
                    t = "#" + t.replace(" ", "")
                if t not in seen:
                    out.append(t)
                    seen.add(t)
                if len(out) >= 12:
                    break
            tags = out or _hashtags(menu_name, store_name, location)

        return LLMOutput(lines, promo, tags)

    except Exception as e:
        logger.warning("LLM í˜¸ì¶œ ì‹¤íŒ¨/íŒŒì‹± ì‹¤íŒ¨. fallbackìœ¼ë¡œ ëŒ€ì²´í•©ë‹ˆë‹¤. err=%s", e)
        return _fallback(
            menu_name=menu_name,
            store_name=store_name,
            tone=tone,
            n_lines=n_lines,
            price=price,
            location=location,
            benefit=benefit,
            cta=cta,
        )
